{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_miIJNrJE3X4"
      },
      "source": [
        "# Deploying our Pneumonia Detection App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msrdSfotHqbl"
      },
      "source": [
        "![](https://journals.plos.org/plosone/article/figure/image?size=medium&id=10.1371/journal.pone.0256630.g014)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYrI1YrYFHde"
      },
      "source": [
        "Now that we have our model trained and set up, we can deploy it as a full scale application to the web! While your site is running, you'll be able to use it on your laptop or computer or share it with friends! We'll be using [Streamlit](https://www.streamlit.io/), a library of website objects and methods that allows us to quickly build a site."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cjHGzmBl_Vh"
      },
      "source": [
        "# Streamlit - Deploying your model to the web\n",
        "\n",
        "The goal of this session is to learn how to deploy the models that we have been training to the web so they can be shared with the world!\n",
        "\n",
        "Let's start with an example.\n",
        "\n",
        "Check out [this example](https://deyb12-poem-image-generator-using-openai-api-poem-app-732rmo.streamlit.app/) and/or [this example](https://bgremoval.streamlit.app/) and answer the following\n",
        "**questions:**\n",
        "* Who is this application for?\n",
        "* How does the user input data - are these intuitive ways of interacting with the app?\n",
        "* What does the application do with the data?\n",
        "* Evaluate the ease of use and look of the application.\n",
        "\n",
        "(More cool examples [here](https://streamlit.io/gallery?category=favorites)!)\n",
        "\n",
        "Today, we'll try to deploy our **pneumonia detection model** to the web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Od_JMBPjfPv",
        "outputId": "e375f223-fd2a-43e6-e7f9-3dd8eea9b986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metadata.csv.1      100%[===================>]  39.56K  --.-KB/s    in 0s      \n",
            "image_data.npy.1    100%[===================>] 131.25M   220MB/s    in 0.6s    \n"
          ]
        }
      ],
      "source": [
        "#@title Run this to download data and prepare our environment!\n",
        "# %tensorflow_version 1.x\n",
        "\n",
        "!pip -q install streamlit > /dev/null\n",
        "!pip -q install pyngrok > /dev/null\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import gdown\n",
        "import cv2\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from pyngrok import ngrok\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from imgaug import augmenters\n",
        "def augment(data, augmenter):\n",
        "  if len(data.shape) == 3:\n",
        "    return augmenter.augment_image(data)\n",
        "  if len(data.shape) == 4:\n",
        "    return augmenter.augment_images(data)\n",
        "\n",
        "def rotate(data, rotate):\n",
        "  fun = augmenters.Affine(rotate = rotate)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def shear(data, shear):\n",
        "  fun = augmenters.Affine(shear = shear)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def scale(data, scale):\n",
        "  fun = augmenters.Affine(scale = scale)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_left_right(data, prob):\n",
        "  fun = augmenters.Fliplr(p = prob)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def flip_up_down(data, prob):\n",
        "  fun = augmenters.Flipud(p = prob)\n",
        "  return augment(data, fun)\n",
        "\n",
        "def remove_color(data, channel):\n",
        "  new_data = data.copy()\n",
        "  if len(data.shape) == 3:\n",
        "    new_data[:,:,channel] = 0\n",
        "    return new_data\n",
        "  if len(data.shape) == 4:\n",
        "    new_data[:,:,:,channel] = 0\n",
        "    return new_data\n",
        "\n",
        "class pkg:\n",
        "  #### DOWNLOADING AND LOADING DATA\n",
        "  def get_metadata(metadata_path, which_splits = ['train', 'test']):\n",
        "    '''returns metadata dataframe which contains columns of:\n",
        "       * index: index of data into numpy data\n",
        "       * class: class of image\n",
        "       * split: which dataset split is this a part of?\n",
        "    '''\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    keep_idx = metadata['split'].isin(which_splits)\n",
        "    return metadata[keep_idx]\n",
        "\n",
        "  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n",
        "    '''\n",
        "    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n",
        "    flattens if flatten option is True\n",
        "    '''\n",
        "    sub_df = metadata[metadata['split'].isin([split_name])]\n",
        "    index  = sub_df['index'].values\n",
        "    labels = sub_df['class'].values\n",
        "    data = all_data[index,:]\n",
        "    if flatten:\n",
        "      data = data.reshape([-1, np.product(image_shape)])\n",
        "    return data, labels\n",
        "\n",
        "  def get_train_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('train', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_test_data(flatten, all_data, metadata, image_shape):\n",
        "    return get_data_split('test', flatten, all_data, metadata, image_shape)\n",
        "\n",
        "  def get_field_data(flatten, all_data, metadata, image_shape):\n",
        "    field_data, field_labels = get_data_split('field', flatten, all_data, metadata, image_shape)\n",
        "    field_data[:,:,:,2] = field_data[:,:,:,0]\n",
        "    field_data[:,:,:,1] = field_data[:,:,:,0]\n",
        "\n",
        "    #make data messier\n",
        "    rand = random.uniform(-1, 1)\n",
        "\n",
        "    for i in range(len(field_data)):\n",
        "      image = field_data[i]\n",
        "\n",
        "      if abs(rand) < 0.5:\n",
        "        image = rotate(image, rotate = rand * 40)\n",
        "      elif abs(rand) < 0.8:\n",
        "        image = shear(image, shear = rand*40)\n",
        "      field_data[i] = image\n",
        "    return field_data, field_labels\n",
        "\n",
        "class helpers:\n",
        "  #### PLOTTING\n",
        "  def plot_one_image(data, labels = [], index = None, image_shape = [64,64,3]):\n",
        "    '''\n",
        "    if data is a single image, display that image\n",
        "\n",
        "    if data is a 4d stack of images, display that image\n",
        "    '''\n",
        "    num_dims   = len(data.shape)\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    # reshape data if necessary\n",
        "    if num_dims == 1:\n",
        "      data = data.reshape(target_shape)\n",
        "    if num_dims == 2:\n",
        "      data = data.reshape(np.vstack[-1, image_shape])\n",
        "    num_dims   = len(data.shape)\n",
        "\n",
        "    # check if single or multiple images\n",
        "    if num_dims == 3:\n",
        "      if num_labels > 1:\n",
        "        print('Multiple labels does not make sense for single image.')\n",
        "        return\n",
        "\n",
        "      label = labels\n",
        "      if num_labels == 0:\n",
        "        label = ''\n",
        "      image = data\n",
        "\n",
        "    if num_dims == 4:\n",
        "      image = data[index, :]\n",
        "      label = labels[index]\n",
        "\n",
        "    # plot image of interest\n",
        "    print('Label: %s'%label)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "  #### QUERYING AND COMBINING DATA\n",
        "  def combine_data(data_list, labels_list):\n",
        "    return np.concatenate(data_list, axis = 0), np.concatenate(labels_list, axis = 0)\n",
        "\n",
        "  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    # i'm sorry for this function's code. i am so sorry.\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')\n",
        "    ax.legend(loc = 4)\n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "class models:\n",
        "  def DenseClassifier(hidden_layer_sizes, nn_params):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape = nn_params['input_shape']))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    for ilayer in hidden_layer_sizes:\n",
        "      model.add(Dense(ilayer, activation = 'relu'))\n",
        "      model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=keras.optimizers.SGD(learning_rate=1e-4, momentum=0.95),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def CNNClassifier(num_hidden_layers, nn_params):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    for i in range(num_hidden_layers-1):\n",
        "        model.add(Conv2D(64, (3, 3), padding = 'same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(units = 128, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(units = 64, activation = 'relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.legacy.RMSprop(learning_rate=1e-5, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss=nn_params['loss'],\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def TransferClassifier(name, nn_params, trainable = False):\n",
        "    expert_dict = {'VGG16': VGG16,\n",
        "                   'VGG19': VGG19,\n",
        "                   'ResNet50':ResNet50,\n",
        "                   'DenseNet121':DenseNet121}\n",
        "\n",
        "    expert_conv = expert_dict[name](weights = 'imagenet',\n",
        "                                              include_top = False,\n",
        "                                              input_shape = nn_params['input_shape'])\n",
        "    for layer in expert_conv.layers:\n",
        "      layer.trainable = trainable\n",
        "\n",
        "    expert_model = Sequential()\n",
        "    expert_model.add(expert_conv)\n",
        "    expert_model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    expert_model.add(Dense(128, activation = 'relu'))\n",
        "    # expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(64, activation = 'relu'))\n",
        "    # expert_model.add(Dropout(0.3))\n",
        "\n",
        "    expert_model.add(Dense(nn_params['output_neurons'], activation = nn_params['output_activation']))\n",
        "\n",
        "    expert_model.compile(loss = nn_params['loss'],\n",
        "                  optimizer = keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return expert_model\n",
        "\n",
        "### defining project variables\n",
        "# file variables\n",
        "metadata_url         = \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/metadata.csv\"\n",
        "image_data_url       = 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/image_data.npy'\n",
        "image_data_path      = './image_data.npy'\n",
        "metadata_path        = './metadata.csv'\n",
        "image_shape          = (64, 64, 3)\n",
        "\n",
        "# neural net parameters\n",
        "nn_params = {}\n",
        "nn_params['input_shape']       = image_shape\n",
        "nn_params['output_neurons']    = 1\n",
        "nn_params['loss']              = 'binary_crossentropy'\n",
        "nn_params['output_activation'] = 'sigmoid'\n",
        "\n",
        "###\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/metadata.csv\"\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20(Healthcare%20A)%20Pneumonia/image_data.npy\"\n",
        "\n",
        "\n",
        "### pre-loading all data of interest\n",
        "_all_data = np.load('image_data.npy')\n",
        "_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n",
        "\n",
        "### preparing definitions\n",
        "# downloading and loading data\n",
        "get_data_split = pkg.get_data_split\n",
        "get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n",
        "get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n",
        "\n",
        "# plotting\n",
        "plot_one_image = lambda data, labels = [], index = None: helpers.plot_one_image(data = data, labels = labels, index = index, image_shape = image_shape);\n",
        "plot_acc       = lambda history: helpers.plot_acc(history)\n",
        "\n",
        "# querying and combining data\n",
        "combine_data           = helpers.combine_data;\n",
        "\n",
        "# models with input parameters\n",
        "DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n",
        "CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n",
        "TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n",
        "\n",
        "monitor = ModelCheckpoint('./model.h5', monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "def launch_website():\n",
        "  print (\"Click this link to try your web app:\")\n",
        "  if (ngrok.get_tunnels() != None):\n",
        "    ngrok.kill()\n",
        "  public_url = ngrok.connect()\n",
        "  print (public_url)\n",
        "  !streamlit run --server.port 80 app.py >/dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMAuRFOklx31"
      },
      "source": [
        "<font color=SlateGrey><h2><b>\n",
        "Use [these](https://drive.google.com/file/d/12zwuOuKh91VSHIHS-6S4ADF4HLC2wKJq/view?usp=sharing) instructions to create a ngrok account and get your authtoken!\n",
        "</b></h2></font>\n",
        "\n",
        "<font color=DarkGray><h3><b>\n",
        "Paste your authtoken below next to `!ngrok authtoken`!\n",
        "</b></h3></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvmMKgftlz5j",
        "outputId": "4c4e530c-d7b2-4ac2-ce73-933d5c136223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2TdcyERyP5WwkVg5gplip4mME5b_4u5WSoJa74MfxPDqyjLyg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJLm_hnPmMM_"
      },
      "source": [
        "## Step 1: Making a website with streamlit\n",
        "\n",
        "Streamlit interprets Python files as a website! This is great for several reasons\n",
        "* No need to know HTML, CSS, Javascript,... etc\n",
        "* Easy to use our trained models which are already in Python!\n",
        "\n",
        "We'll write everything to a file called app.py, which is used for Streamlit to launch the site.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZJP9IQOmvV8",
        "outputId": "4b464a3f-38ec-4261-dc11-9353e8b6c7f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"Pneumonia Detection\")\n",
        "st.header(\"Description of the app\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z21OHfkXl82E",
        "outputId": "9d302026-3611-424d-93ac-0af2f9363a3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-07T03:07:42+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Click this link to try your web app:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-07T03:07:43+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"https://cefa-35-245-17-35.ngrok-free.app\" -> \"http://localhost:80\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "#Publish Web App (Run this again whenever you make changes)\n",
        "launch_website()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21apfMGTnquH"
      },
      "source": [
        "## Step 2: Loading the model\n",
        "\n",
        "Since the focus of this session is deployment we'll skip over training the model and just load one that we've already trained :)\n",
        "\n",
        "Here is a reference on how to save and load sklearn and tensorflow models!\n",
        "\n",
        "For sklearn:\n",
        "```\n",
        "from joblib import dump, load\n",
        "\n",
        "# ====== Save model ========\n",
        "dump(model, 'filename.joblib')\n",
        "\n",
        "# ====== Load model ========\n",
        "clf = load('filename.joblib')\n",
        "```\n",
        "\n",
        "For tensorflow:\n",
        "```\n",
        "import tensorflow as tf\n",
        "\n",
        "# ====== Save model ========\n",
        "model.save(\"filename.h5\")\n",
        "\n",
        "# ====== Load model ========\n",
        "tf.keras.models.load_model(\"filename.h5\")\n",
        "```\n",
        "\n",
        "Our model today is going to be a tensorflow model! Let's load in the model we created last time:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bZNwh4tmvn5",
        "outputId": "a244b9fb-4de0-431b-ed5e-83b441e52148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "cnn_path = F\"/content/gdrive/My Drive/cnn.zip\"\n",
        "\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9j7yvdXNzOT"
      },
      "source": [
        "We can set it to model and double check its shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxSscLB7v02u"
      },
      "outputs": [],
      "source": [
        "# Load your model\n",
        "model = tf.keras.models.load_model(\"cnn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqtYap1OwPcr",
        "outputId": "8f814f84-bf97-405c-958b-bcd3056688a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_29 (Conv2D)          (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 32, 32, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 128)               2097280   \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,124,993\n",
            "Trainable params: 2,124,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG7GJI1MwgLJ"
      },
      "source": [
        "## Step 3: Accept file uploads\n",
        "\n",
        "We want to allow the user of the website to upload their own images to our website for our model to make predictions on. This can be accomplished by the following line:\n",
        "\n",
        "`f = st.file_uploader(\"Upload Image\")`\n",
        "\n",
        "We can then extract and display with the following lines of code\n",
        "\n",
        "```\n",
        "if f is not None:\n",
        "  file_bytes = np.asarray(bytearray(f.read()), dtype=np.uint8)\n",
        "  image = cv2.imdecode(file_bytes, 1)\n",
        "  st.image(image, channels=\"BGR\")\n",
        "```\n",
        "\n",
        "Exercise: Add this code to app.py, run the website and try it out!\n",
        "\n",
        "Hint: Dont forget to\n",
        "\n",
        "`import numpy as np`\n",
        "\n",
        "and\n",
        "\n",
        "`import cv2`\n",
        "\n",
        "at the top of the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3UUT4u_OKPP",
        "outputId": "1daa9d77-0b89-4d2d-bb8f-6c087edccfd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import zipfile\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Extract the CNN model from the zip file\n",
        "cnn_path = \"/content/gdrive/My Drive/cnn.zip\"\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "# Load the CNN model\n",
        "cnn =tf.keras.models.load_model(\"cnn\")\n",
        "\n",
        "# Create a Title\n",
        "st.title(\"Pneumonia Detection\")\n",
        "st.header(\"Description of the app\")\n",
        "\n",
        "# Function to process the uploaded image into a format that the model can use\n",
        "def process_image(image):\n",
        "    # Convert the image to RGB mode\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "    # Resize the image\n",
        "    image = image.resize((64, 64))\n",
        "\n",
        "    # Convert the image to an array and normalize\n",
        "    img_array = np.array(image).astype('float32')\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Expand dimensions to match the expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Display the image upload widget using st.file_uploader\n",
        "f = st.file_uploader(\"Upload Image\")\n",
        "\n",
        "# Perform prediction and display the result\n",
        "if f is not None:\n",
        "    # Read the uploaded image\n",
        "    image = Image.open(f)\n",
        "\n",
        "    # Process and classify the image\n",
        "    processed_image = process_image(image)\n",
        "    prediction = cnn.predict(processed_image)\n",
        "    diagnoses = (prediction > 0.5).astype(int)\n",
        "    pred_diagnosis = \"Pneumonia\" if diagnoses else \"No Pneumonia\"\n",
        "\n",
        "    # Display the processed image\n",
        "    st.image(image)\n",
        "\n",
        "    # Display the predicted diagnosis\n",
        "    st.header(\"Prediction\")\n",
        "    st.subheader(\"Diagnosis\")\n",
        "    st.write(pred_diagnosis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI6skyW4QRfC"
      },
      "source": [
        "While running your site, you can try fetching some images from our original dataset below. You can download the image by right-clicking the generated image and `Save image as...` before uploading it to your site!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Q6-67Rs_QYA4",
        "outputId": "12e76428-b369-406d-bf47-0197ebd10090"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: No Pneumonia\n"
          ]
        }
      ],
      "source": [
        "#@title Fetch Image { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Load the image data\n",
        "image_data = np.load('image_data.npy')\n",
        "\n",
        "# Load the metadata\n",
        "metadata = pkg.get_metadata(metadata_path, ['train', 'test'])\n",
        "\n",
        "# Choose an index to download the corresponding image\n",
        "input_index = \"12\" #@param {type:\"string\"}\n",
        "index = int(input_index)\n",
        "\n",
        "# Get the image from the data array\n",
        "image = image_data[index]\n",
        "\n",
        "# Remove the extra channel if it exists\n",
        "if image.shape[-1] == 4:\n",
        "    image = image[:, :, :3]\n",
        "\n",
        "# Create a PIL image object\n",
        "pil_image = Image.fromarray(np.uint8(image))\n",
        "\n",
        "# Get the label for the image using the metadata\n",
        "label = metadata.iloc[index]['class']  # Replace 'class' with the appropriate column name in your metadata\n",
        "if label == 0:\n",
        "    label = 'No Pneumonia'\n",
        "else:\n",
        "    label = 'Pneumonia'\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title('Image')\n",
        "plt.show()\n",
        "\n",
        "# Print the label to the terminal\n",
        "print(f'Label: {label}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgWjdatpFYzl",
        "outputId": "be34e1f5-72aa-416c-d48e-23cf367c9ad2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-07T03:12:39+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Click this link to try your web app:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-07T03:12:39+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"https://3ea8-35-245-17-35.ngrok-free.app\" -> \"http://localhost:80\"\n",
            "2023-08-07 03:12:54.227953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "#Publish Web App (Run this again whenever you make changes)\n",
        "launch_website()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqLHpRwyXjSX"
      },
      "source": [
        "#### (Optional, if time permits) Spend some time thinking about better ways to visualize and use the model, and update app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2JNKkKlFe_Q"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import zipfile\n",
        "import base64\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Extract the CNN model from the zip file\n",
        "cnn_path = \"/content/gdrive/My Drive/cnn.zip\"\n",
        "with zipfile.ZipFile(cnn_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "# Load the CNN model\n",
        "cnn = # YOUR CODE HERE\n",
        "\n",
        "# Create a Title\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Function to process the uploaded image into a format that the model can use\n",
        "def process_image(image):\n",
        "    # Convert the image to RGB mode\n",
        "    image = image.convert('RGB')\n",
        "\n",
        "    # Resize the image\n",
        "    image = image.resize((64, 64))\n",
        "\n",
        "    # Convert the image to an array and normalize\n",
        "    img_array = np.array(image).astype('float32')\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # Expand dimensions to match the expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Display the image upload widget using st.file_uploader\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Perform prediction and display the result\n",
        "if uploaded_file is not None:\n",
        "    # Read the uploaded image\n",
        "    image = Image.open(YOUR CODE HERE)\n",
        "\n",
        "    # Process and classify the image\n",
        "    processed_image = YOUR CODE HERE\n",
        "    prediction = YOUR CODE HERE\n",
        "    diagnoses = YOUR CODE HERE\n",
        "    pred_diagnosis = YOUR CODE HERE\n",
        "\n",
        "    # Display the processed image\n",
        "    YOUR CODE HERE\n",
        "\n",
        "    # Display the predicted diagnosis\n",
        "    st.header(\"Prediction\")\n",
        "    st.subheader(\"Diagnosis\")\n",
        "    st.write(pred_diagnosis)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}